{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Consolidate the Database\n",
    "\n",
    "This step consolidates the `.xlsx` files generated in Step 2 into a unified database for analysis. The `all_text` column, created during this step, enhances the database for later semantic search operations by combining the `question` and `answers` columns into a single text field.\n",
    "\n",
    "#### **Workflow**:\n",
    "1. Process individual `.xlsx` files:\n",
    "   - Standardize column names to `filename`, `question`, and `answers`.\n",
    "   - Add an `Index` column for unique identification of rows.\n",
    "   - Save the processed files in the `Database` folder.\n",
    "2. Create a consolidated database:\n",
    "   - Read all standardized `.xlsx` files from the `Database` folder.\n",
    "   - Combine `question` and `answers` into a new `all_text` column for semantic searches.\n",
    "   - Save the consolidated database as `ALL_PROCESSED.xlsx`.\n",
    "\n",
    "#### **Inputs**:\n",
    "- `.xlsx` files from the `Reviewed` folder.\n",
    "\n",
    "#### **Outputs**:\n",
    "- Standardized `.xlsx` files in the `Database` folder.\n",
    "- A consolidated database file (`ALL_PROCESSED.xlsx`) with an `all_text` column for semantic analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Individual Files\n",
    "\n",
    "The code block below processes all `.xlsx` files in the `Reviewed` folder:\n",
    "1. Reads each file into a DataFrame.\n",
    "2. Standardizes column names to `filename`, `question`, and `answers`.\n",
    "3. Adds an `Index` column.\n",
    "4. Saves the standardized version of the file to the `Database` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 0)  # Adapt the number as needed for your screen\n",
    "\n",
    "# Directories\n",
    "input_directory = \"Reviewed\"\n",
    "output_directory = \"Database\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Loop through all files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "        filepath = os.path.join(input_directory, filename)\n",
    "        \n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(filepath)\n",
    "\n",
    "        # Ensure the first three columns have the names \"country\", \"question\", \"answers\"\n",
    "        if len(df.columns) >= 3:\n",
    "            df.columns.values[0:3] = ['filename', 'question', 'answers']\n",
    "        \n",
    "        # Add a new column with index numbers\n",
    "        df['Index'] = range(1, len(df) + 1)\n",
    "        \n",
    "        # Save the modified DataFrame to the output directory\n",
    "        output_filepath = os.path.join(output_directory, filename)\n",
    "        df.to_excel(output_filepath, index=False)\n",
    "\n",
    "        print(f\"Processed and saved: {filename} to {output_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate All Files into a Unified Database\n",
    "\n",
    "Next code block combines all standardized `.xlsx` files from the `Database` folder:\n",
    "1. Reads each file into a DataFrame.\n",
    "2. Ensures both `question` and `answers` columns exist; otherwise, creates an empty `all_text` column.\n",
    "3. Concatenates `question` and `answers` into a new column `all_text`.\n",
    "4. Appends all DataFrames into a single comprehensive DataFrame.\n",
    "5. Saves the final database to `Database/ALL_PROCESSED.xlsx`.\n",
    "\n",
    "##### **Purpose of `all_text`**:\n",
    "The `all_text` column enables advanced semantic search functionality by merging `question` and `answers` into a single searchable field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all country files into one data frame\n",
    "directory = \"Database\"\n",
    "\n",
    "# List to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Get all files in the directory and sort them alphabetically\n",
    "files = sorted([f for f in os.listdir(directory) if f.endswith(\".xlsx\")])\n",
    "\n",
    "# Loop through the sorted list of files\n",
    "for filename in files:\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    # Read each Excel file into a DataFrame\n",
    "    df = pd.read_excel(filepath)\n",
    "    \n",
    "    # Check if both 'question' and 'answers' columns exist\n",
    "    if 'question' in df.columns and 'answers' in df.columns:\n",
    "        # Concatenate 'question' and 'answers' into a new column 'all_text'\n",
    "        df['all_text'] = df['question'].astype(str) + \" \" + df['answers'].astype(str)\n",
    "    else:\n",
    "        # If either column is missing, add an empty 'all_text' column\n",
    "        df['all_text'] = \"\"\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "all_data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the concatenated DataFrame to a new Excel file\n",
    "all_data.to_excel(\"Database/ALL_PROCESSED.xlsx\", index=False)\n",
    "\n",
    "# View the structure\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append Metadata Mapping\n",
    "\n",
    "This section adds metadata information to the consolidated database using a separate metadata files (`Files_selected.xlsx`) and (`Files_selected.xlsx`)\n",
    "\n",
    "#### Purpose:\n",
    "Appending metadata information enriches the consolidated database by adding contextual details for each processed file. This is useful for downstream analysis and maintaining traceability of the data. Importantly, it adds infomration about the location of each file on ILO's internal drives.\n",
    "\n",
    "#### Notes:\n",
    "- The metadata file (`Files_selected.xlsx`) is available only to authorized ILO officials and is not included in the publicly available GitHub repository.\n",
    "- Ensure the metadata file is correctly formatted and accessible in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append metadata from the main tracking file and additional regional labels for each country\n",
    "\n",
    "# Read file with country labels from STATS\n",
    "labels = pd.read_excel(\"/Data/LFS_labels.xlsx\")\n",
    "\n",
    "# Read metadata mapping of processed files\n",
    "metadata_df = pd.read_excel(\"Files_selected.xlsx\")\n",
    "\n",
    "# Get the unique values of the 'filename' column from the 'all_data' dataframe\n",
    "unique_files_processed = pd.DataFrame(all_data['filename'].unique(), columns=['filename'])\n",
    "print(unique_files_processed)\n",
    "\n",
    "# Merge the metadata into the full_data based on the 'filename' column\n",
    "full_data = all_data.merge(metadata_df, on='filename', how='left')\n",
    "\n",
    "# Rename the columns \n",
    "full_data = full_data.rename(columns={\n",
    "    'filename': 'filename_processed',\n",
    "    'Index': 'question_index',\n",
    "    'value': 'questionnaire_filename',\n",
    "    'path_Q': 'path',\n",
    "    'ref_area': 'country',\n",
    "    'time': 'year'\n",
    "})\n",
    "\n",
    "# Create a new column 'full_path' by concatenating 'path' and 'filename_questionnaire'\n",
    "full_data['full_path'] = full_data['path'] + full_data['questionnaire_filename']\n",
    "\n",
    "# Reorganize the columns in the desired order, drop those that are not of interest \n",
    "full_data = full_data[[\n",
    "    'country', 'year', 'source', 'question_index', 'question', 'answers', \n",
    "    'questionnaire_filename', 'path', 'full_path', 'filename_processed', 'all_text'\n",
    "]]\n",
    "\n",
    "# Merge the labels into the full_data based on the 'question_index' or any other common column\n",
    "full_data_with_labels = full_data.merge(labels, on='country', how='left')  # Adjust the 'on' column as needed\n",
    "\n",
    "# Save the reorganized DataFrame to a new Excel file\n",
    "full_data_with_labels.to_excel(\"Database/ALL_PROCESSED_METADATA.xlsx\", index=False)\n",
    "\n",
    "# Display the first 5 rows of the reorganized dataframe\n",
    "full_data_with_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save key stats of the database into a separate file\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "\n",
    "# 1. Number of distinct countries\n",
    "distinct_countries = all_data['country'].nunique()\n",
    "\n",
    "# 2. Number of rows per country\n",
    "rows_per_country = all_data['country'].value_counts()\n",
    "\n",
    "# 3. Total number of rows in the file\n",
    "total_rows = len(all_data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of distinct countries: {distinct_countries}\")\n",
    "print(f\"Total number of rows: {total_rows}\")\n",
    "print(\"\\nNumber of rows per country:\")\n",
    "print(rows_per_country)\n",
    "\n",
    "# Create a DataFrame to store the overview results\n",
    "stats_df = pd.DataFrame({\n",
    "    'Statistic': ['Number of distinct countries', 'Total number of rows'],\n",
    "    'Value': [distinct_countries, total_rows]\n",
    "})\n",
    "\n",
    "# Remove the '.xlsx' extension from the country names (if applicable)\n",
    "rows_per_country.index = rows_per_country.index.str.replace('.xlsx', '', regex=False)\n",
    "\n",
    "# Convert rows_per_country Series to DataFrame and reset index\n",
    "rows_per_country_df = rows_per_country.reset_index()\n",
    "rows_per_country_df.columns = ['Country', 'Number of Rows']\n",
    "\n",
    "# Sort the DataFrame by the 'Country' column\n",
    "rows_per_country_df = rows_per_country_df.sort_values(by='Country')\n",
    "\n",
    "# Create a bar plot for the number of rows per country\n",
    "plt.figure(figsize=(16, 12))\n",
    "bars = plt.bar(rows_per_country.index, rows_per_country.values, color='skyblue')\n",
    "\n",
    "# Add a title and labels\n",
    "plt.title('Number of Questions per Country', fontsize=18)\n",
    "plt.xlabel('Country', fontsize=14)\n",
    "plt.ylabel('Number of Questions', fontsize=14)\n",
    "\n",
    "# Rotate x-axis labels to 90 degrees\n",
    "plt.xticks(rotation=90, fontsize=9)\n",
    "\n",
    "# Add labels on top of each bar rotated at 90 degrees\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,  # X position\n",
    "        height + max(rows_per_country.values) * 0.01,  # Slightly above the bar\n",
    "        f'{int(height)}',  # Label text\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        rotation=90,\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "# Adjust layout to fit all elements nicely\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to a BytesIO object\n",
    "plot_image = BytesIO()\n",
    "plt.savefig(plot_image, format='png')\n",
    "plt.close()  # Close the plot to free up memory\n",
    "plot_image.seek(0)  # Go to the beginning of the BytesIO object\n",
    "\n",
    "# Save all information into a single sheet in Main_stats.xlsx\n",
    "with pd.ExcelWriter(\"Database_Main_stats.xlsx\", engine='xlsxwriter') as writer:\n",
    "    stats_df.to_excel(writer, sheet_name='Statistics', index=False, startrow=0)\n",
    "    rows_per_country_df.to_excel(writer, sheet_name='Statistics', index=False, startrow=4)\n",
    "\n",
    "    # Access the workbook and worksheet\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Statistics']\n",
    "\n",
    "    # Set the width of the first column to be three times its default size\n",
    "    worksheet.set_column('A:A', 30)  # Set column A (first column) to be 30 units wide\n",
    "    worksheet.set_column('B:B', 20)  # Set column A (first column) to be 30 units wide\n",
    "    # Insert the plot into the worksheet\n",
    "    worksheet.insert_image('E2', 'Rows per Country Plot', {'image_data': plot_image})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this step, we:\n",
    "1. Standardized individual `.xlsx` files generated in Step 2.\n",
    "2. Merged all files into a single, unified database for analysis.\n",
    "3. Created an automated overview of the database, with a countr of countries, Q-A pairs, years covered, etc.\n",
    "\n",
    "### Next Steps\n",
    "The consolidated database (`Database/ALL_PROCESSED_METADATA.xlsx`) is now ready for further analysis or integration in subsequent steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
